# Back-end - Sistema de An√°lise de Pol√≠ticas de Privacidade

Esta √© a API back-end para o sistema de an√°lise automatizada de pol√≠ticas de privacidade, desenvolvida como parte de um desafio t√©cnico. A aplica√ß√£o √© constru√≠da com Node.js, Fastify, TypeScript e Prisma, integrando web scraping e intelig√™ncia artificial (Google Gemini) para classifica√ß√£o autom√°tica de conte√∫do, seguindo as melhores pr√°ticas de desenvolvimento de software para garantir um c√≥digo limpo, escal√°vel e de f√°cil manuten√ß√£o.

## Links Relacionados

- **[üè† Projeto Principal](../)** - Raiz do reposit√≥rio
- **[üìñ Swagger Documentation](http://localhost:3333/docs)** - Documenta√ß√£o interativa da API
- **[üîó API Base URL](http://localhost:3333)** - Endpoint base da API (desenvolvimento)
- **[‚öôÔ∏è Configura√ß√£o Docker](../docker-compose.yml)** - Setup completo com Docker
- **[ü§ñ Google Gemini API](https://ai.google.dev/)** - Documenta√ß√£o da API de IA utilizada

---

## Tabela de Conte√∫dos

- [Filosofia e Estrutura do Projeto](#filosofia-e-estrutura-do-projeto)
  - [Estrutura de M√≥dulos](#estrutura-de-m√≥dulos)
  - [Arquitetura em Camadas](#arquitetura-em-camadas)
  - [Estrutura de Pastas](#estrutura-de-pastas)
  - [Valida√ß√£o e Tipagem](#valida√ß√£o-e-tipagem)
- [Decis√µes T√©cnicas](#decis√µes-t√©cnicas)
  - [Funcionamento do Web Scraping](#funcionamento-do-web-scraping)
  - [An√°lise por Intelig√™ncia Artificial](#an√°lise-por-intelig√™ncia-artificial)
- [Script de Ingest√£o de Dados](#script-de-ingest√£o-de-dados)
  - [Como Usar o Script](#como-usar-o-script)
  - [Demonstra√ß√£o em V√≠deo](#demonstra√ß√£o-em-v√≠deo)
- [Como Iniciar o Projeto](#como-iniciar-o-projeto)
  - [Pr√©-requisitos](#pr√©-requisitos)
  - [Passo a Passo](#passo-a-passo)
- [Executando os Testes](#executando-os-testes)
  - [Op√ß√£o 1: Script Automatizado (Recomendado)](#op√ß√£o-1-script-automatizado-recomendado)
  - [Op√ß√£o 2: Comandos Manuais via `package.json`](#op√ß√£o-2-comandos-manuais-via-packagejson)
- [Endpoints da API](#endpoints-da-api)
- [Poss√≠veis Melhorias](#poss√≠veis-melhorias)

---

## Filosofia e Estrutura do Projeto

A principal decis√£o arquitetural foi organizar o c√≥digo de forma modular e desacoplada, facilitando a manuten√ß√£o e a adi√ß√£o de novas funcionalidades.

### Estrutura de M√≥dulos

O projeto adota uma estrutura de **Feature-Sliced Design**. Dentro de `src/modules`, cada funcionalidade principal (`policies`, `scraping`, `ai`, `ingestion`) √© um m√≥dulo autocontido. Cada m√≥dulo possui:

- `*.controller.ts`: Respons√°vel por receber as requisi√ß√µes HTTP, validar os dados de entrada e retornar as respostas. Nenhuma regra de neg√≥cio reside aqui.
- `*.service.ts`: Cont√©m a l√≥gica de neg√≥cio da funcionalidade. Orquestra as opera√ß√µes e utiliza o reposit√≥rio para acessar o banco de dados.
- `*.repository.ts`: Camada de abstra√ß√£o do acesso a dados. √â o √∫nico local que interage diretamente com o Prisma para consultas ao banco de dados.
- `*.routes.ts`: Define as rotas da API para o m√≥dulo, associando-as aos m√©todos do controller.
- `*.schema.ts`: Define os schemas de valida√ß√£o com **Zod** para os dados de entrada (body, params, query) e para as respostas da API, garantindo a integridade dos dados e servindo como base para a documenta√ß√£o OpenAPI (Swagger).
- `*.types.ts`: Define as interfaces e tipos TypeScript para a funcionalidade.

### Arquitetura em Camadas

A comunica√ß√£o entre os componentes segue um fluxo unidirecional claro (Controller ‚Üí Service ‚Üí Repository), o que torna o c√≥digo previs√≠vel e f√°cil de depurar.

1. **Controller**: Camada de entrada da aplica√ß√£o.
2. **Service**: O "c√©rebro" de cada funcionalidade.
3. **Repository**: A "m√£o" que busca e manipula os dados.

Essa separa√ß√£o de responsabilidades (SoC) √© fundamental para a testabilidade e escalabilidade do projeto.

### Estrutura de Pastas

A organiza√ß√£o das pastas segue a l√≥gica modular descrita anteriormente, separando claramente as responsabilidades e facilitando a navega√ß√£o.

```text
.
‚îú‚îÄ‚îÄ prisma/                  # Cont√©m o schema do banco de dados e as migra√ß√µes.
‚îÇ   ‚îî‚îÄ‚îÄ schema.prisma
‚îú‚îÄ‚îÄ scripts/                 # Scripts √∫teis para o projeto.
‚îÇ   ‚îú‚îÄ‚îÄ run-ingestion-service.ts # Script para ingerir e analisar pol√≠ticas de privacidade.
‚îÇ   ‚îî‚îÄ‚îÄ test-integration.sh  # Script para rodar os testes de integra√ß√£o de forma automatizada.
‚îú‚îÄ‚îÄ src/                     # C√≥digo-fonte da aplica√ß√£o.
‚îÇ   ‚îú‚îÄ‚îÄ core/                # N√∫cleo da aplica√ß√£o (configura√ß√µes n√£o relacionadas a neg√≥cio).
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/          # Configura√ß√£o de vari√°veis de ambiente.
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database/        # Configura√ß√£o da conex√£o com o banco de dados (Prisma).
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ webserver/       # Configura√ß√µes do servidor Fastify (app, error handler).
‚îÇ   ‚îú‚îÄ‚îÄ modules/             # M√≥dulos de neg√≥cio da aplica√ß√£o.
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai/              # M√≥dulo de Intelig√™ncia Artificial (Google Gemini).
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingestion/       # M√≥dulo de Ingest√£o (orquestra√ß√£o do processo).
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ policies/        # M√≥dulo de Pol√≠ticas de Privacidade.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraping/        # M√≥dulo de Web Scraping.
‚îÇ   ‚îú‚îÄ‚îÄ utils/               # Utilit√°rios gerais da aplica√ß√£o.
‚îÇ   ‚îî‚îÄ‚îÄ server.ts            # Ponto de entrada (entry point) que inicia o servidor.
‚îú‚îÄ‚îÄ tests/                   # Su√≠te de testes automatizados.
‚îÇ   ‚îú‚îÄ‚îÄ helpers/             # C√≥digo de suporte para os testes (ex: setup do app).
‚îÇ   ‚îî‚îÄ‚îÄ integration/         # Testes de integra√ß√£o para cada m√≥dulo.
‚îú‚îÄ‚îÄ .dockerignore            # Arquivos a serem ignorados pelo Docker.
‚îú‚îÄ‚îÄ .env.example             # Arquivo de exemplo para as vari√°veis de ambiente.
‚îú‚îÄ‚îÄ docker-compose.test.yml  # Docker Compose para o ambiente de testes.
‚îú‚îÄ‚îÄ docker-compose.yml       # Docker Compose para o ambiente de desenvolvimento.
‚îú‚îÄ‚îÄ Dockerfile               # Define a imagem Docker para a aplica√ß√£o.
‚îú‚îÄ‚îÄ package.json             # Depend√™ncias e scripts do projeto.
‚îú‚îÄ‚îÄ tsconfig.json            # Configura√ß√µes do compilador TypeScript.
‚îî‚îÄ‚îÄ vitest.config.ts         # Configura√ß√µes do Vitest.
```

### Valida√ß√£o e Tipagem

- **TypeScript**: Utilizado em todo o projeto para garantir a seguran√ßa de tipos e melhorar a experi√™ncia de desenvolvimento.
- **Zod**: Para valida√ß√£o de schemas em tempo de execu√ß√£o. Ele previne que dados inv√°lidos cheguem √†s camadas de neg√≥cio e ao banco de dados, al√©m de gerar documenta√ß√£o autom√°tica para as rotas.

---

## Decis√µes T√©cnicas

### Funcionamento do Web Scraping

O sistema de web scraping foi projetado com uma estrat√©gia de fallback para garantir m√°xima compatibilidade com diferentes tipos de websites:

1. **M√©todo Principal - Axios + Cheerio**: 
   - Primeira tentativa usando requisi√ß√µes HTTP simples com Axios
   - Parsing do HTML com Cheerio para extrair conte√∫do
   - Mais r√°pido e eficiente em recursos
   - Funciona bem com sites que n√£o dependem de JavaScript

2. **M√©todo Fallback - Puppeteer**:
   - Utilizado quando o m√©todo principal falha
   - Renderiza p√°ginas JavaScript com um navegador real (Chromium)
   - Mais lento mas compat√≠vel com SPAs e sites din√¢micos
   - Suporta sites que requerem intera√ß√£o do usu√°rio

3. **Estrat√©gias de Extra√ß√£o**:
   - Seletores espec√≠ficos para sites conhecidos (Google, Facebook, etc.)
   - Algoritmo gen√©rico baseado em densidade de texto para sites desconhecidos
   - Limpeza autom√°tica de conte√∫do desnecess√°rio (navega√ß√£o, footers, etc.)

### An√°lise por Intelig√™ncia Artificial

A classifica√ß√£o de conte√∫do utiliza o **Google Gemini 2.5 Flash Lite** com as seguintes caracter√≠sticas:

1. **Categoriza√ß√£o Predefinida**:
   - 12 categorias espec√≠ficas para pol√≠ticas de privacidade
   - Inclui: Dados Pessoais, Dados Financeiros, Localiza√ß√£o, Cookies, etc.

2. **Otimiza√ß√µes de Custo**:
   - Limita√ß√£o do conte√∫do enviado para an√°lise (m√°ximo 20.000 caracteres)
   - Uso da vers√£o "lite" do modelo para reduzir custos

3. **Prompt Engineering**:
   - Prompt estruturado para garantir consist√™ncia nas respostas
   - Instru√ß√µes espec√≠ficas para retorno em formato JSON
   - Contexto sobre LGPD e regulamenta√ß√µes de privacidade brasileiras

---

## Script de Ingest√£o de Dados

O script de ingest√£o automatiza todo o processo de coleta, an√°lise e armazenamento de pol√≠ticas de privacidade.

### Como Usar o Script

1. **Configure as vari√°veis de ambiente**:
   ```bash
   # Adicione sua chave da API do Google Gemini no arquivo .env
   GOOGLE_AI_API_KEY=sua_chave_aqui
   ```

2. **Execute o script de ingest√£o**:
   ```bash
   npm run ingestion
   ```

3. **O script ir√°**:
   - Fazer scraping das URLs predefinidas
   - Analisar o conte√∫do com IA
   - Classificar em categorias
   - Salvar no banco de dados

### URLs Predefinidas

O script vem configurado com as seguintes pol√≠ticas de privacidade:
- Google Privacy Policy
- Facebook Privacy Policy  
- Microsoft Privacy Statement
- Apple Privacy Policy
- Amazon Privacy Notice

### Demonstra√ß√£o em V√≠deo

**üìπ [ESPA√áO RESERVADO PARA V√çDEO DEMONSTRATIVO]**

*Aqui ser√° inserido um v√≠deo demonstrando:*
- *Execu√ß√£o do script de ingest√£o*
- *Processo de scraping em tempo real*
- *Classifica√ß√£o pela IA*
- *Resultados salvos no banco de dados*
- *Consulta dos dados via API*

**‚ö†Ô∏è Importante**: O script de scraping e an√°lise por IA **n√£o est√° dispon√≠vel em produ√ß√£o** para evitar custos elevados com as APIs de intelig√™ncia artificial. Em ambiente de produ√ß√£o, os dados s√£o previamente processados e inseridos manualmente no banco de dados.

---

## Como Iniciar o Projeto

Siga os passos abaixo para configurar e executar o ambiente de desenvolvimento localmente.

### Pr√©-requisitos

- **Node.js**: v22.18 ou superior
- **Docker** e **Docker Compose**
- **NPM** (ou um gerenciador de pacotes de sua prefer√™ncia)
- **Chave API do Google Gemini** (para funcionalidades de IA)

### Passo a Passo

1. **Navegue at√© a pasta do projeto**:

   ```bash
   cd backend
   ```

2. **Instale as depend√™ncias**:

   ```bash
   npm install
   ```

3. **Configure as Vari√°veis de Ambiente**:
   Copie o arquivo de exemplo `.env.example` para um novo arquivo chamado `.env`.

   ```bash
   cp .env.example .env
   ```

   **Configure as seguintes vari√°veis importantes**:
   ```env
   DATABASE_URL="postgresql://user:password@localhost:5432/privacy_policies"
   GOOGLE_AI_API_KEY="sua_chave_do_google_gemini_aqui"
   ```

4. **Inicie os Containers**:
   Na raiz do reposit√≥rio, execute o comando:

   ```bash
   docker-compose up -d
   ```

5. **Execute as Migrations do Banco de Dados**:
   Com os containers em execu√ß√£o, aplique as migrations para criar as tabelas.

   **OBS**: Esse passo s√≥ precisa ser feito na primeira execu√ß√£o do projeto ou quando h√° alguma altera√ß√£o no schema.

   ```bash
   docker exec -it node_api npm run prisma:migrate
   ```

6. **Execute o script de ingest√£o inicial** (opcional):
   Para popular o banco com dados de exemplo:

   ```bash
   npm run ingestion
   ```

Pronto! A API estar√° em execu√ß√£o e acess√≠vel em `http://localhost:3333`.

---

## Executando os Testes

Os testes de integra√ß√£o foram desenvolvidos com **Vitest** e **Supertest** e rodam em um banco de dados de teste separado e isolado para garantir que n√£o afetem os dados de desenvolvimento.

### Op√ß√£o 1: Script Automatizado (Recomendado)

Para facilitar a execu√ß√£o dos testes, foi criado um script que cuida de todo o ciclo de vida do ambiente de teste.

- **O que o script faz?**
  1.  Sobe o banco de dados de teste com Docker.
  2.  Aplica as migrations no banco de teste.
  3.  Executa a su√≠te de testes do Vitest.
  4.  Derruba o container do banco de dados de teste ao final.

- **Como executar?**
  Na raiz da pasta `backend-nodejs`, execute o comando:
  ```bash
  sh ./scripts/test-integration.sh
  ```

### Op√ß√£o 2: Comandos Manuais via `package.json`

Se preferir ter mais controle sobre o processo, voc√™ pode executar os testes manualmente.

1.  **Inicie o banco de dados de teste**:

    ```bash
    docker-compose -f docker-compose.test.yml up -d
    ```

2.  **Execute as migrations no banco de teste**:

    ```bash
    npm run test:db:migrate
    ```

3.  **Execute um dos seguintes comandos**:
    - Para rodar todos os testes uma vez:
      ```bash
      npm test
      ```
    - Para rodar os testes em modo "watch", ideal para desenvolvimento:
      ```bash
      npm run test:watch
      ```
    - Para rodar os testes e gerar um relat√≥rio de cobertura:
      ```bash
      npm run test:coverage
      ```

4.  **Desligue o banco de dados de teste** quando terminar:
    ```bash
    docker-compose -f docker-compose.test.yml down
    ```

---

## Endpoints da API

Abaixo est√° um resumo dos principais endpoints dispon√≠veis. Para detalhes sobre os schemas de request e response, consulte a documenta√ß√£o OpenAPI/Swagger gerada pela aplica√ß√£o. A documenta√ß√£o completa √© executada na rota `/docs`.

| M√©todo   | Rota                      | Descri√ß√£o                                                    |
| :------- | :------------------------ | :----------------------------------------------------------- |
| `POST`   | `/api/policies`           | Cria uma nova pol√≠tica de privacidade.                      |
| `GET`    | `/api/policies`           | Lista todas as pol√≠ticas de privacidade.                    |
| `GET`    | `/api/policies/:id`       | Busca uma pol√≠tica espec√≠fica por ID.                       |
| `PUT`    | `/api/policies/:id`       | Atualiza uma pol√≠tica de privacidade existente.             |
| `DELETE` | `/api/policies/:id`       | Deleta uma pol√≠tica de privacidade.                         |

### Filtros e Pagina√ß√£o

A rota GET `/api/policies/` oferece os seguintes par√¢metros:

- **`term`** (string, obrigat√≥rio): Termo de busca
- **`page`** (number, opcional): P√°gina atual (padr√£o: 1)  
- **`page_size`** (number, opcional): Itens por p√°gina (padr√£o: 10, m√°ximo: 50)

### Categorias Dispon√≠veis

As pol√≠ticas s√£o classificadas automaticamente nas seguintes categorias:

- `DADOS PESSOAIS GERAIS`
- `DADOS FINANCEIROS` 
- `DADOS LOCALIZACAO`
- `COOKIES TRACKING`
- `MARKETING PUBLICIDADE`
- `COMPARTILHAMENTO TERCEIROS`
- `SEGURANCA PROTECAO`
- `DIREITOS USUARIO`
- `RETENCAO DADOS`
- `MENORES IDADE`
- `TRANSFERENCIA INTERNACIONAL`
- `OUTROS`

---

## Poss√≠veis Melhorias

Esta se√ß√£o documenta melhorias que poderiam ser implementadas para tornar o sistema mais robusto e escal√°vel em um ambiente de produ√ß√£o:

### 1. Inje√ß√£o de Depend√™ncias Melhorada
- **Problema atual**: Depend√™ncias s√£o instanciadas diretamente nos construtores
- **Melhoria proposta**: Implementar um container de IoC (Invers√£o de Controle) como `tsyringe` ou `inversify`
- **Benef√≠cios**: Melhor testabilidade, flexibilidade e desacoplamento

### 2. Download e Processamento de Arquivos PDF
- **Limita√ß√£o atual**: Sistema processa apenas conte√∫do HTML
- **Melhoria proposta**: Adicionar suporte para extra√ß√£o de texto de PDFs usando `pdf-parse` ou `pdf2pic`
- **Casos de uso**: Muitas pol√≠ticas de privacidade s√£o distribu√≠das como PDFs

### 3. Separa√ß√£o de Responsabilidades Refinada
- **√Årea de melhoria**: M√≥dulo de scraping com m√∫ltiplas responsabilidades
- **Proposta**: Separar em `ScrapingStrategy`, `ContentExtractor`, e `URLValidator`
- **Padr√£o**: Implementar Strategy Pattern para diferentes tipos de extra√ß√£o

### 4. Monitoramento e Observabilidade
- **Ausente atualmente**: M√©tricas de performance e logging estruturado
- **Ferramentas sugeridas**: Prometheus + Grafana, Winston, OpenTelemetry
- **M√©tricas importantes**: Taxa de sucesso de scraping, tempo de resposta da IA, erros por endpoint

### 5. Testes de Carga e Performance
- **Gap atual**: Apenas testes de integra√ß√£o
- **Adi√ß√£o**: Testes com Artillery ou k6 para simular carga real
- **Cen√°rios**: M√∫ltiplas requisi√ß√µes simult√¢neas de scraping e classifica√ß√£o

---

## Links Relacionados

- **[ Projeto Principal](../)** - Raiz do reposit√≥rio
- **[üìñ Swagger Documentation](http://localhost:3333/docs)** - Documenta√ß√£o interativa da API
- **[üîó API Base URL](http://localhost:3333)** - Endpoint base da API (desenvolvimento)
- **[‚öôÔ∏è Configura√ß√£o Docker](../docker-compose.yml)** - Setup completo com Docker
- **[ü§ñ Google Gemini API](https://ai.google.dev/)** - Documenta√ß√£o da API de IA utilizada
